//! Routines to check the database format version and migrate it if necessary.
#![allow(clippy::too_many_lines)]
mod migration_structures;

use std::{
    fs::{File, create_dir_all},
    io::{Read, Write},
    path::{Path, PathBuf},
};

use anyhow::{Context, Result, anyhow};
use semver::{Version, VersionReq};
use tracing::info;

/// The range of versions that use the current database format.
///
/// The range should include all the earlier, released versions that use the
/// current database format, and exclude the first future version that uses a
/// new database format.
///
/// # Examples
///
/// ```rust
/// // [Case 1: Stable Patch Version, No Format Change]
/// // The current version is 0.4.1 and the database format hasn't been changed
/// // since 0.3.0. This should include future patch versions such as 0.4.2,
/// // 0.4.3, etc. since they won't change the database format.
/// const COMPATIBLE_VERSION: &str = ">=0.3,<0.5.0-alpha";
/// ```
///
/// ```rust
/// // [Case 2: Alpha Patch Version, No RocksDB Format Change]
/// // The current version is 3.4.6-alpha.2 and the database format hasn't been
/// // changed since 1.0.0. Future pre-release versions such as 3.4.6-alpha.3
/// // are compatible since they won't change the database format.
/// const COMPATIBLE_VERSION: &str = ">=1.0.0,<3.5.0-alpha";
/// ```
///
/// ```rust
/// // [Case 3: Transition to New Alpha Version, No RocksDB Format Change]
/// // The current version is 3.4.5 and the database format hasn't been changed
/// // since 1.0.0. The next version to pre-release is 3.5.0-alpha.1, if no
/// // database format change is involved, then compatible version should be
/// // extended to 3.5.0-alpha.1.
/// const COMPATIBLE_VERSION: &str = ">=1.0.0,<=3.5.0-alpha.1";
/// ```
///
/// ```rust
/// // [Case 4: Transition to Stable Major Version, No RocksDB Format Change]
/// // The current version is 3.4.5 and the database format hasn't been changed
/// // since 1.0.0. The next version to release is 3.5.0 (stable), if no
/// // database format change is involved, then migration is not needed, while
/// // compatible version should be extended to 3.5.0., including all future
/// // patch versions.
/// const COMPATIBLE_VERSION: &str = ">=1.0.0,<3.6.0-alpha";
/// ```
///
/// ```rust
/// // [Case 5: Transition from Alpha to Stable Version, No RocksDB Format Change]
/// // The current version is 3.4.5-alpha.3 and the database format hasn't been
/// // changed since 1.0.0. The next version to release is 3.5.0 (stable), with
/// // compatibility extended to future patch versions.
/// const COMPATIBLE_VERSION: &str = ">=1.0.0,<3.6.0-alpha";
/// ```
///
/// ```rust
/// // [Case 6: Transition to New Alpha Version, RocksDB Format Change]
/// // The current version is 3.4.5 and the database format is changing in
/// // 3.5.0-alpha.1. The compatibility is now restricted to 3.5.0-alpha.1,
/// // requiring a migration from the 1.0.0 format.
/// const COMPATIBLE_VERSION: &str = ">=3.5.0-alpha.1,<3.5.0-alpha.2";
/// // Migration: `migrate_1_0_to_3_5` must handle changes from 1.0.0 to
/// // 3.5.0-alpha.1.
/// ```
///
/// ```rust
/// // [Case 7: Transition Between Alpha Versions, RocksDB Format Change]
/// // The current version is 3.5.0-alpha.2 and the database format is changing in
/// // 3.5.0-alpha.3. The compatibility is now restricted to 3.5.0-alpha.3,
/// // requiring a migration from the 1.0.0 format.
/// const COMPATIBLE_VERSION: &str = ">=3.5.0-alpha.3,<3.5.0-alpha.4";
/// // Migration: `migrate_1_0_to_3_5` must handle changes from 1.0.0 to
/// // 3.5.0-alpha.3, including prior alpha changes.
///```
///
/// ```rust
/// // [Case 8: Transition from Alpha to Stable Version, RocksDB Format Finalized]
/// // The current version is 3.5.0-alpha.2 and the database format is
/// // finalized in 3.5.0. The compatibility is extended to all 3.5.0 versions,
/// // requiring a migration from the 1.0.0 format.
/// const COMPATIBLE_VERSION: &str = ">=3.5.0,<3.6.0-alpha";
/// // Migration: `migrate_1_0_to_3_5` must handle changes from 1.0.0 (last
/// // release that involves database format change) to 3.5.0, including
/// // all alpha changes finalized in 3.5.0.
/// ```
const COMPATIBLE_VERSION_REQ: &str = ">=0.43.0-alpha.1,<0.43.0-alpha.2";

/// Migrates the data directory to the up-to-date format if necessary.
///
/// Migration is supported between released versions only. The prelease versions (alpha, beta,
/// etc.) should be assumed to be incompatible with each other.
///
/// # Errors
///
/// Returns an error if the data directory doesn't exist and cannot be created,
/// or if the data directory exists but is in the format incompatible with the
/// current version.
pub fn migrate_data_dir<P: AsRef<Path>>(data_dir: P, backup_dir: P) -> Result<()> {
    type Migration = (VersionReq, Version, fn(&Path, &Path) -> anyhow::Result<()>);

    let data_dir = data_dir.as_ref();
    let backup_dir = backup_dir.as_ref();

    let Ok(compatible) = VersionReq::parse(COMPATIBLE_VERSION_REQ) else {
        unreachable!("COMPATIBLE_VERSION_REQ must be valid")
    };

    let (data, data_ver) = retrieve_or_create_version(data_dir)?;
    let (backup, backup_ver) = retrieve_or_create_version(backup_dir)?;

    if data_ver != backup_ver {
        return Err(anyhow!(
            "mismatched database version {data_ver} and backup version {backup_ver}"
        ));
    }

    let mut version = data_ver;
    if compatible.matches(&version) {
        return Ok(());
    }

    // A list of migrations where each item is a tuple of (version requirement, to version,
    // migration function).
    //
    // * The "version requirement" should include all the earlier, released versions that use the
    //   database format the migration function can handle, and exclude the first future version
    //   that uses a new database format.
    // * The "to version" should be the first future version that uses a new database format.
    // * The "migration function" should migrate the database from the version before "to version"
    //   to "to version". The function name should be in the form of "migrate_A_to_B" where A is
    //   the first version (major.minor) in the "version requirement" and B is the "to version"
    //   (major.minor). (NOTE: Once we release 1.0.0, A and B will contain the major version only.)
    let migration: Vec<Migration> = vec![(
        VersionReq::parse(">=0.42.0-alpha.5,<0.43.0-alpha.1")?,
        Version::parse("0.43.0-alpha.1")?,
        migrate_0_42_to_0_43,
    )];

    while let Some((_req, to, m)) = migration
        .iter()
        .find(|(req, _to, _m)| req.matches(&version))
    {
        info!("Migrating database to {to}");
        m(data_dir, backup_dir)?;
        version = to.clone();
        if compatible.matches(&version) {
            create_version_file(&backup).context("failed to update VERSION")?;
            return create_version_file(&data).context("failed to update VERSION");
        }
    }

    Err(anyhow!("migration from {version} is not supported",))
}

/// Column family names for version 0.42 (includes the deprecated "account policy" column family)
const MAP_NAMES_V0_42: [&str; 36] = [
    "access_tokens",
    "accounts",
    "account policy",
    "agents",
    "allow networks",
    "batch_info",
    "block networks",
    "category",
    "cluster",
    "column stats",
    "configs",
    "csv column extras",
    "customers",
    "data sources",
    "filters",
    "hosts",
    "models",
    "model indicators",
    "meta",
    "networks",
    "nodes",
    "outliers",
    "qualifiers",
    "external services",
    "sampling policy",
    "scores",
    "statuses",
    "templates",
    "TI database",
    "time series",
    "Tor exit nodes",
    "traffic filter rules",
    "triage policy",
    "triage response",
    "trusted DNS servers",
    "trusted user agents",
];

fn migrate_0_42_to_0_43(data_dir: &Path, backup_dir: &Path) -> Result<()> {
    let db_path = data_dir.join("states.db");
    let backup_path = backup_dir.join("states.db");

    info!("Opening database with legacy column families");

    // Open the database with the old column family names (including "account policy")
    let mut opts = rocksdb::Options::default();
    opts.create_if_missing(false);
    opts.create_missing_column_families(false);

    let mut db: rocksdb::OptimisticTransactionDB =
        rocksdb::OptimisticTransactionDB::open_cf(&opts, &db_path, MAP_NAMES_V0_42)
            .context("Failed to open database with legacy column families")?;

    // Perform data migrations for TriagePolicy and Tidb
    info!("Migrating TriagePolicy and Tidb data");

    // Get column family handles
    let triage_policy_cf: &rocksdb::ColumnFamily = match db.cf_handle("triage policy") {
        Some(cf) => cf,
        None => anyhow::bail!("Failed to find triage policy column family"),
    };
    let tidb_cf: &rocksdb::ColumnFamily = match db.cf_handle("TI database") {
        Some(cf) => cf,
        None => anyhow::bail!("Failed to find TI database column family"),
    };

    // Migrate TriagePolicy
    {
        use bincode::Options;

        use self::migration_structures::TriagePolicyV0_42;
        use crate::TriagePolicy;

        let mut updates = Vec::new();
        let iter = db.iterator_cf(triage_policy_cf, rocksdb::IteratorMode::Start);
        for item in iter {
            let (key, value) = item.context("Failed to read from database")?;

            let old_policy: TriagePolicyV0_42 = bincode::DefaultOptions::new()
                .deserialize(value.as_ref())
                .context("Failed to deserialize old triage policy")?;

            let new_policy = TriagePolicy::from(old_policy);
            let new_value = bincode::DefaultOptions::new()
                .serialize(&new_policy)
                .context("Failed to serialize new triage policy")?;

            updates.push((key.to_vec(), new_value));
        }

        for (key, value) in updates {
            db.put_cf(triage_policy_cf, &key, &value)?;
        }
    }

    // Migrate Tidb
    {
        use bincode::Options;

        use self::migration_structures::TidbV0_42;
        use crate::Tidb;

        let mut updates = Vec::new();
        let iter = db.iterator_cf(tidb_cf, rocksdb::IteratorMode::Start);
        for item in iter {
            let (key, value) = item.context("Failed to read from database")?;

            let old_tidb: TidbV0_42 = bincode::DefaultOptions::new()
                .deserialize(value.as_ref())
                .context("Failed to deserialize old tidb")?;

            let new_tidb = Tidb::from(old_tidb);
            let new_value = bincode::DefaultOptions::new()
                .serialize(&new_tidb)
                .context("Failed to serialize new tidb")?;

            updates.push((key.to_vec(), new_value));
        }

        for (key, value) in updates {
            db.put_cf(tidb_cf, &key, &value)?;
        }
    }

    // Drop the "account policy" column family
    info!("Dropping 'account policy' column family");
    db.drop_cf("account policy")
        .context("Failed to drop 'account policy' column family")?;

    // Close the database by dropping it
    drop(db);

    // Also perform migration on backup database
    let mut backup_db: rocksdb::OptimisticTransactionDB =
        rocksdb::OptimisticTransactionDB::open_cf(&opts, &backup_path, MAP_NAMES_V0_42)
            .context("Failed to open backup database with legacy column families")?;

    let backup_triage_policy_cf: &rocksdb::ColumnFamily = match backup_db.cf_handle("triage policy")
    {
        Some(cf) => cf,
        None => anyhow::bail!("Failed to find triage policy column family in backup"),
    };
    let backup_tidb_cf: &rocksdb::ColumnFamily = match backup_db.cf_handle("TI database") {
        Some(cf) => cf,
        None => anyhow::bail!("Failed to find TI database column family in backup"),
    };

    // Migrate TriagePolicy in backup
    {
        use bincode::Options;

        use self::migration_structures::TriagePolicyV0_42;
        use crate::TriagePolicy;

        let mut updates = Vec::new();
        let iter = backup_db.iterator_cf(backup_triage_policy_cf, rocksdb::IteratorMode::Start);
        for item in iter {
            let (key, value) = item.context("Failed to read from backup database")?;

            let old_policy: TriagePolicyV0_42 = bincode::DefaultOptions::new()
                .deserialize(value.as_ref())
                .context("Failed to deserialize old triage policy from backup")?;

            let new_policy = TriagePolicy::from(old_policy);
            let new_value = bincode::DefaultOptions::new()
                .serialize(&new_policy)
                .context("Failed to serialize new triage policy for backup")?;

            updates.push((key.to_vec(), new_value));
        }

        for (key, value) in updates {
            backup_db.put_cf(backup_triage_policy_cf, &key, &value)?;
        }
    }

    // Migrate Tidb in backup
    {
        use bincode::Options;

        use self::migration_structures::TidbV0_42;
        use crate::Tidb;

        let mut updates = Vec::new();
        let iter = backup_db.iterator_cf(backup_tidb_cf, rocksdb::IteratorMode::Start);
        for item in iter {
            let (key, value) = item.context("Failed to read from backup database")?;

            let old_tidb: TidbV0_42 = bincode::DefaultOptions::new()
                .deserialize(value.as_ref())
                .context("Failed to deserialize old tidb from backup")?;

            let new_tidb = Tidb::from(old_tidb);
            let new_value = bincode::DefaultOptions::new()
                .serialize(&new_tidb)
                .context("Failed to serialize new tidb for backup")?;

            updates.push((key.to_vec(), new_value));
        }

        for (key, value) in updates {
            backup_db.put_cf(backup_tidb_cf, &key, &value)?;
        }
    }

    info!("Dropping 'account policy' column family from backup");
    backup_db
        .drop_cf("account policy")
        .context("Failed to drop 'account policy' column family from backup")?;

    drop(backup_db);

    info!("Successfully removed 'account policy' column family");
    Ok(())
}

/// Recursively creates `path` if not existed, creates the VERSION file
/// under `path` if missing with current version number. Returns VERSION
/// file path with VERSION number written on file.
///
/// # Errors
///
/// Returns an error if VERSION cannot be retrieved or created.
fn retrieve_or_create_version<P: AsRef<Path>>(path: P) -> Result<(PathBuf, Version)> {
    let path = path.as_ref();
    let file = path.join("VERSION");

    if !path.exists() {
        create_dir_all(path)?;
    }
    if path
        .read_dir()
        .context("cannot read data dir")?
        .next()
        .is_none()
    {
        create_version_file(&file)?;
    }

    let version = read_version_file(&file)?;
    Ok((file, version))
}

/// Creates the VERSION file in the data directory.
///
/// # Errors
///
/// Returns an error if the VERSION file cannot be created or written.
fn create_version_file(path: &Path) -> Result<()> {
    let mut f = File::create(path).context("cannot create VERSION")?;
    f.write_all(env!("CARGO_PKG_VERSION").as_bytes())
        .context("cannot write VERSION")?;
    Ok(())
}

/// Reads the VERSION file in the data directory and returns its contents.
///
/// # Errors
///
/// Returns an error if the VERSION file cannot be read or parsed.
fn read_version_file(path: &Path) -> Result<Version> {
    let mut ver = String::new();
    File::open(path)
        .context("cannot open VERSION")?
        .read_to_string(&mut ver)
        .context("cannot read VERSION")?;
    Version::parse(&ver).context("cannot parse VERSION")
}

#[cfg(test)]
mod tests {
    use semver::{Version, VersionReq};

    use super::COMPATIBLE_VERSION_REQ;
    use crate::Store;

    #[allow(dead_code)]
    struct TestSchema {
        db_dir: tempfile::TempDir,
        backup_dir: tempfile::TempDir,
        store: Store,
    }

    impl TestSchema {
        #[allow(dead_code)]
        fn new() -> Self {
            let db_dir = tempfile::tempdir().unwrap();
            let backup_dir = tempfile::tempdir().unwrap();
            let store = Store::new(db_dir.path(), backup_dir.path()).unwrap();
            TestSchema {
                db_dir,
                backup_dir,
                store,
            }
        }

        #[allow(dead_code)]
        fn new_with_dir(db_dir: tempfile::TempDir, backup_dir: tempfile::TempDir) -> Self {
            let store = Store::new(db_dir.path(), backup_dir.path()).unwrap();
            TestSchema {
                db_dir,
                backup_dir,
                store,
            }
        }

        #[allow(dead_code)]
        fn close(self) -> (tempfile::TempDir, tempfile::TempDir) {
            (self.db_dir, self.backup_dir)
        }
    }

    #[test]
    fn version() {
        let compatible = VersionReq::parse(COMPATIBLE_VERSION_REQ).expect("valid semver");
        let current = Version::parse(env!("CARGO_PKG_VERSION")).expect("valid semver");

        // The current version must match the compatible version requirement.
        if current.pre.is_empty() {
            assert!(compatible.matches(&current));
        } else if current.major == 0 && current.patch != 0 || current.major >= 1 {
            // A pre-release for a backward-compatible version.
            let non_pre = Version::new(current.major, current.minor, current.patch);
            assert!(compatible.matches(&non_pre));
        } else {
            assert!(compatible.matches(&current));
        }

        // A future, backward-incompatible version must not match the compatible version.
        let breaking = {
            let mut breaking = current;
            if breaking.major == 0 {
                breaking.minor += 1;
            } else {
                breaking.major += 1;
            }
            breaking
        };
        assert!(!compatible.matches(&breaking));
    }

    #[test]
    fn migrate_0_42_to_0_43_drops_account_policy() {
        use std::fs;
        use std::io::Write;

        // Create test directories
        let db_dir = tempfile::tempdir().unwrap();
        let backup_dir = tempfile::tempdir().unwrap();

        let db_path = db_dir.path().join("states.db");
        let backup_path = backup_dir.path().join("states.db");

        // Create a database with the old column family list (including "account policy")
        let mut opts = rocksdb::Options::default();
        opts.create_if_missing(true);
        opts.create_missing_column_families(true);

        let db: rocksdb::OptimisticTransactionDB =
            rocksdb::OptimisticTransactionDB::open_cf(&opts, &db_path, super::MAP_NAMES_V0_42)
                .unwrap();
        drop(db);

        let backup_db: rocksdb::OptimisticTransactionDB =
            rocksdb::OptimisticTransactionDB::open_cf(&opts, &backup_path, super::MAP_NAMES_V0_42)
                .unwrap();
        drop(backup_db);

        // Create VERSION files with 0.42.0-alpha.5
        let mut version_file = fs::File::create(db_dir.path().join("VERSION")).unwrap();
        version_file.write_all(b"0.42.0-alpha.5").unwrap();
        drop(version_file);

        let mut backup_version_file = fs::File::create(backup_dir.path().join("VERSION")).unwrap();
        backup_version_file.write_all(b"0.42.0-alpha.5").unwrap();
        drop(backup_version_file);

        // Run the migration
        super::migrate_0_42_to_0_43(db_dir.path(), backup_dir.path()).unwrap();

        // Verify the column family has been dropped by opening with the new list
        let db: rocksdb::OptimisticTransactionDB =
            rocksdb::OptimisticTransactionDB::open_cf(&opts, &db_path, crate::tables::MAP_NAMES)
                .unwrap();

        // Try to access "account policy" - should fail since it was dropped
        assert!(db.cf_handle("account policy").is_none());

        // Close and reopen to ensure it still works
        drop(db);

        let db: rocksdb::OptimisticTransactionDB =
            rocksdb::OptimisticTransactionDB::open_cf(&opts, &db_path, crate::tables::MAP_NAMES)
                .unwrap();
        assert!(db.cf_handle("account policy").is_none());
        drop(db);

        // Verify backup database too
        let backup_db: rocksdb::OptimisticTransactionDB =
            rocksdb::OptimisticTransactionDB::open_cf(
                &opts,
                &backup_path,
                crate::tables::MAP_NAMES,
            )
            .unwrap();
        assert!(backup_db.cf_handle("account policy").is_none());

        // Close and reopen backup database to ensure it still works
        drop(backup_db);

        let backup_db: rocksdb::OptimisticTransactionDB =
            rocksdb::OptimisticTransactionDB::open_cf(
                &opts,
                &backup_path,
                crate::tables::MAP_NAMES,
            )
            .unwrap();
        assert!(backup_db.cf_handle("account policy").is_none());
    }
}
